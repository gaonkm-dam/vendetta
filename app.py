# ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨ - ë‹¨ì¼ íŒŒì¼ ë²„ì „ (Streamlit Cloud í˜¸í™˜)
# modules, config ì—†ì´ ëª¨ë“  ê¸°ëŠ¥ í†µí•©

import streamlit as st
import os
import json
import sqlite3
import base64
from datetime import datetime, date
from io import BytesIO
from typing import Dict, Any, Optional, List, Tuple
from contextlib import contextmanager
from zipfile import ZipFile
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI import
try:
    from openai import OpenAI
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key and hasattr(st, 'secrets'):
        api_key = st.secrets.get("OPENAI_API_KEY", "")
    if not api_key:
        st.error("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloud Secretsì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()
    client = OpenAI(api_key=api_key)
except Exception as e:
    st.error(f"OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

# PIL import
try:
    from PIL import Image
except:
    st.error("Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— pillow>=10.0.0 ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ReportLab import
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import mm
    from reportlab.pdfgen import canvas
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.cidfonts import UnicodeCIDFont
except:
    st.error("ReportLab ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— reportlab>=4.0.0 ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ==================== ì„¤ì • (Settings) ====================

DB_PATH = "data/policies.db"

TARGET_AUDIENCES = {
    "ì‹œë¯¼": {
        "tone": "ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´",
        "focus": "ì¼ìƒ ìƒí™œ í˜œíƒ, ì‹¤ìƒí™œ ë³€í™”"
    },
    "ì²­ë…„": {
        "tone": "íŠ¸ë Œë””í•˜ê³  ì§ê´€ì ì¸",
        "focus": "ê¸°íšŒ í™•ëŒ€, ë¯¸ë˜ ì „ë§"
    },
    "ë…¸ì¸": {
        "tone": "ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ",
        "focus": "ì•ˆì „, í¸ì˜ì„±, ì ‘ê·¼ì„±"
    },
    "í•™ë¶€ëª¨": {
        "tone": "ì‹ ë¢°ê° ìˆê³  êµ¬ì²´ì ì¸",
        "focus": "ìë…€ ì•ˆì „, êµìœ¡ íš¨ê³¼"
    },
    "ê¸°ì—…": {
        "tone": "ì „ë¬¸ì ì´ê³  íš¨ìœ¨ì ì¸",
        "focus": "ë¹„ìš© ì ˆê°, ê·œì œ ì™„í™”, ROI"
    },
    "ì§€ìì²´ ê³µë¬´ì›": {
        "tone": "ì²´ê³„ì ì´ê³  ì‹¤ë¬´ì ì¸",
        "focus": "ì‹¤í–‰ ê°€ëŠ¥ì„±, ì˜ˆì‚°, ë²•ì  ê·¼ê±°"
    },
    "ì˜íšŒ/ì˜ì›": {
        "tone": "ì„¤ë“ì ì´ê³  ê·¼ê±° ì¤‘ì‹¬",
        "focus": "ì •ì±… íš¨ê³¼, êµ­ë¯¼ ì²´ê°, ì„±ê³¼ ì§€í‘œ"
    }
}

VIDEO_PLATFORMS = {
    "Sora": "https://sora.openai.com",
    "Runway": "https://runwayml.com",
    "Pika": "https://pika.art",
    "Luma Dream Machine": "https://lumalabs.ai"
}

IMAGE_SIZES = ["1024x1024", "1024x1792", "1792x1024"]
VIDEO_DURATIONS = ["10ì´ˆ", "20ì´ˆ", "30ì´ˆ", "60ì´ˆ"]

CONTENT_PACKAGES = {
    "A ë§ˆì¼€íŒ…": ["ì´ë¯¸ì§€ 2ì¥", "ì˜ìƒ 1ê°œ", "í™ë³´ ë¬¸êµ¬ 3ì¢…"],
    "B ì •ì±… ì„¤ëª…": ["ì •ì±… ìš”ì•½", "PPT êµ¬ì„±", "FAQ"],
    "C í’€ íŒ¨í‚¤ì§€": ["ì´ë¯¸ì§€ 4ì¥", "ì˜ìƒ 2ê°œ", "í™ë³´ ë¬¸êµ¬ 5ì¢…", "ì •ì±… ë¬¸ì„œ", "PPT", "ì„±ê³¼ ì§€í‘œ"]
}

DEFAULT_IMAGE_STYLE = """
Professional documentary photography, ultra-realistic, photojournalistic style.
Location: Modern South Korea (Seoul, Busan, or other major Korean cities).
Architecture: Contemporary Korean buildings, clean streets, realistic urban/suburban settings.
People: Natural Korean faces with accurate facial features, realistic expressions.
DO NOT distort faces - maintain natural human proportions and features.
Lighting: Natural daylight, soft shadows, professional photography lighting.
Color palette: Natural, slightly desaturated, clean and modern aesthetic.
Atmosphere: Authentic everyday Korean life, genuine moments.
Technical requirements:
- High resolution, sharp focus on main subjects
- Proper depth of field
- Realistic skin tones (Korean complexion)
- Natural body proportions
- Clear, undistorted facial features
- Professional color grading
Forbidden elements:
- NO text, logos, signs with readable text
- NO distorted or warped faces
- NO unrealistic proportions
- NO stock photo feel
- NO overly posed or artificial scenes
- NO generic Asian stereotypes
Style reference: Korean documentary photography, modern Korean cinema aesthetics.
"""

# ==================== ë°ì´í„°ë² ì´ìŠ¤ (Database) ====================

@contextmanager
def get_db():
    # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs("data", exist_ok=True)
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

def init_database():
    with get_db() as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS policies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                category TEXT NOT NULL,
                target_audience TEXT NOT NULL,
                description TEXT,
                status TEXT DEFAULT 'draft',
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS policy_contents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                policy_id INTEGER NOT NULL,
                content_type TEXT NOT NULL,
                content_data TEXT NOT NULL,
                metadata TEXT,
                created_at TEXT NOT NULL,
                FOREIGN KEY (policy_id) REFERENCES policies(id)
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS policy_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                policy_id INTEGER NOT NULL,
                view_count INTEGER DEFAULT 0,
                engagement_score REAL DEFAULT 0.0,
                feedback_data TEXT,
                metrics_data TEXT,
                updated_at TEXT NOT NULL,
                FOREIGN KEY (policy_id) REFERENCES policies(id)
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS generated_media (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                policy_id INTEGER NOT NULL,
                media_type TEXT NOT NULL,
                media_url TEXT,
                media_data BLOB,
                prompt TEXT,
                generation_params TEXT,
                created_at TEXT NOT NULL,
                FOREIGN KEY (policy_id) REFERENCES policies(id)
            )
        """)
        
        conn.commit()

def create_policy(title: str, category: str, target_audience: str, description: str = "") -> int:
    now = datetime.now().isoformat()
    with get_db() as conn:
        cursor = conn.execute("""
            INSERT INTO policies (title, category, target_audience, description, status, created_at, updated_at)
            VALUES (?, ?, ?, ?, 'draft', ?, ?)
        """, (title, category, target_audience, description, now, now))
        conn.commit()
        return cursor.lastrowid

def update_policy_status(policy_id: int, status: str):
    now = datetime.now().isoformat()
    with get_db() as conn:
        conn.execute("""
            UPDATE policies SET status = ?, updated_at = ? WHERE id = ?
        """, (status, now, policy_id))
        conn.commit()

def save_policy_content(policy_id: int, content_type: str, content_data: Dict[str, Any], metadata: Optional[Dict] = None):
    now = datetime.now().isoformat()
    with get_db() as conn:
        conn.execute("""
            INSERT INTO policy_contents (policy_id, content_type, content_data, metadata, created_at)
            VALUES (?, ?, ?, ?, ?)
        """, (
            policy_id,
            content_type,
            json.dumps(content_data, ensure_ascii=False),
            json.dumps(metadata or {}, ensure_ascii=False),
            now
        ))
        conn.commit()

def save_generated_media(policy_id: int, media_type: str, media_data: bytes, prompt: str, params: Dict[str, Any]):
    now = datetime.now().isoformat()
    with get_db() as conn:
        conn.execute("""
            INSERT INTO generated_media (policy_id, media_type, media_data, prompt, generation_params, created_at)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            policy_id,
            media_type,
            media_data,
            prompt,
            json.dumps(params, ensure_ascii=False),
            now
        ))
        conn.commit()

def get_policy(policy_id: int) -> Optional[Dict[str, Any]]:
    with get_db() as conn:
        row = conn.execute("SELECT * FROM policies WHERE id = ?", (policy_id,)).fetchone()
        if row:
            return dict(row)
        return None

def get_all_policies(limit: int = 50) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policies ORDER BY created_at DESC LIMIT ?
        """, (limit,)).fetchall()
        return [dict(row) for row in rows]

def get_policy_contents(policy_id: int) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policy_contents WHERE policy_id = ? ORDER BY created_at DESC
        """, (policy_id,)).fetchall()
        results = []
        for row in rows:
            data = dict(row)
            data['content_data'] = json.loads(data['content_data'])
            data['metadata'] = json.loads(data['metadata']) if data['metadata'] else {}
            results.append(data)
        return results

def get_generated_media(policy_id: int, media_type: Optional[str] = None) -> List[Dict[str, Any]]:
    with get_db() as conn:
        if media_type:
            rows = conn.execute("""
                SELECT * FROM generated_media WHERE policy_id = ? AND media_type = ? ORDER BY created_at DESC
            """, (policy_id, media_type)).fetchall()
        else:
            rows = conn.execute("""
                SELECT * FROM generated_media WHERE policy_id = ? ORDER BY created_at DESC
            """, (policy_id,)).fetchall()
        
        results = []
        for row in rows:
            data = dict(row)
            data['generation_params'] = json.loads(data['generation_params']) if data['generation_params'] else {}
            results.append(data)
        return results

def get_policies_by_date(date_str: str) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policies 
            WHERE date(created_at) = date(?)
            ORDER BY created_at DESC
        """, (date_str,)).fetchall()
        return [dict(row) for row in rows]

def get_policies_by_date_range(start_date: str, end_date: str) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policies 
            WHERE date(created_at) BETWEEN date(?) AND date(?)
            ORDER BY created_at DESC
        """, (start_date, end_date)).fetchall()
        return [dict(row) for row in rows]

# ==================== AI ì—”ì§„ (AI Engine) ====================

def parse_json_response(text: str) -> Optional[Dict]:
    text = text.strip()
    if text.startswith("```"):
        text = text.replace("```json", "").replace("```", "").strip()
    try:
        return json.loads(text)
    except:
        return None

def generate_policy_analysis(
    title: str,
    category: str,
    target_audience: str,
    description: str,
    keywords: str = "",
    constraints: str = "",
    model: str = "gpt-4o"
) -> Tuple[Optional[Dict], str]:
    
    prompt = f"""
ë‹¹ì‹ ì€ ì •ì„¸ë‹´ ì •ì±… ìë™í™” ì‹œìŠ¤í…œì˜ AIì…ë‹ˆë‹¤.
ì •ì±…ì˜ ê¸°íšë¶€í„° ì‹¤í–‰, í™ë³´, ì„±ê³¼ê´€ë¦¬ê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]
ì •ì±… ì œëª©: {title}
ì •ì±… ì¹´í…Œê³ ë¦¬: {category}
ëŒ€ìƒ: {target_audience}
ì •ì±… ì„¤ëª…: {description}
ê°•ì¡° í‚¤ì›Œë“œ: {keywords}
ì œì•½ ì¡°ê±´: {constraints}

[ì¶œë ¥ ê·œì¹™]
- ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥
- í•œêµ­ í˜„ì‹¤ì— ë§ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©
- ê³¼ì¥ ê¸ˆì§€, ì¸¡ì • ê°€ëŠ¥í•œ ì§€í‘œ ì‚¬ìš©
- ëŒ€ìƒì— ë§ëŠ” í†¤ê³¼ ë©”ì‹œì§€

[JSON ìŠ¤í‚¤ë§ˆ]
{{
  "policy_planning": {{
    "objective": "ì •ì±… ëª©í‘œ (3-5ë¬¸ì¥)",
    "target_analysis": "ëŒ€ìƒ ë¶„ì„ (ë‹ˆì¦ˆ, íŠ¹ì„±, ì ‘ê·¼ë²• 3-5ë¬¸ì¥)",
    "key_strategies": ["í•µì‹¬ ì „ëµ 5-8ê°œ"],
    "expected_outcomes": ["ê¸°ëŒ€ íš¨ê³¼ 5-7ê°œ"],
    "timeline": {{
      "preparation": "ì¤€ë¹„ ë‹¨ê³„ ë‚´ìš©",
      "pilot": "ì‹œë²” ìš´ì˜ ë‚´ìš©",
      "expansion": "í™•ëŒ€ ì ìš© ë‚´ìš©"
    }}
  }},
  
  "execution_plan": {{
    "action_items": [
      {{
        "phase": "ë‹¨ê³„ëª…",
        "action": "ì‹¤í–‰ ë‚´ìš©",
        "responsible": "ë‹´ë‹¹ ì£¼ì²´",
        "timeline": "ì†Œìš” ê¸°ê°„"
      }}
    ],
    "resources_needed": {{
      "budget_range": "ì˜ˆì‚° ë²”ìœ„ (êµ¬ì²´ì  ê¸ˆì•¡ ëŒ€ì‹  ë²”ì£¼)",
      "personnel": "í•„ìš” ì¸ë ¥",
      "infrastructure": "í•„ìš” ì¸í”„ë¼"
    }},
    "risk_management": [
      {{
        "risk": "ë¦¬ìŠ¤í¬ í•­ëª©",
        "impact": "ì˜í–¥ë„",
        "mitigation": "ì™„í™” ë°©ì•ˆ"
      }}
    ]
  }},
  
  "communication_strategy": {{
    "key_messages": ["í•µì‹¬ ë©”ì‹œì§€ 5-8ê°œ"],
    "channels": [
      {{
        "channel": "ì±„ë„ëª…",
        "content_type": "ì½˜í…ì¸  í˜•ì‹",
        "frequency": "ë°œí–‰ ì£¼ê¸°"
      }}
    ],
    "target_specific_messages": {{
      "citizens": "ì‹œë¯¼ ëŒ€ìƒ ë©”ì‹œì§€",
      "youth": "ì²­ë…„ ëŒ€ìƒ ë©”ì‹œì§€",
      "elderly": "ë…¸ì¸ ëŒ€ìƒ ë©”ì‹œì§€",
      "parents": "í•™ë¶€ëª¨ ëŒ€ìƒ ë©”ì‹œì§€"
    }}
  }},
  
  "content_briefs": {{
    "image_brief_1": {{
      "concept": "ì´ë¯¸ì§€ ì»¨ì…‰ (5-7ë¬¸ì¥)",
      "scene_description": "ì¥ë©´ ìƒì„¸ ë¬˜ì‚¬ (10-15ë¬¸ì¥)",
      "visual_style": "ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (ì´¬ì˜ ê¸°ë²•, ì¡°ëª…, ìƒ‰ê°)",
      "key_message": "ì „ë‹¬í•  í•µì‹¬ ë©”ì‹œì§€"
    }},
    "image_brief_2": {{
      "concept": "ì´ë¯¸ì§€ ì»¨ì…‰ (5-7ë¬¸ì¥)",
      "scene_description": "ì¥ë©´ ìƒì„¸ ë¬˜ì‚¬ (10-15ë¬¸ì¥)",
      "visual_style": "ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (ì´¬ì˜ ê¸°ë²•, ì¡°ëª…, ìƒ‰ê°)",
      "key_message": "ì „ë‹¬í•  í•µì‹¬ ë©”ì‹œì§€"
    }},
    "video_brief": {{
      "duration": "ì˜ìƒ ê¸¸ì´",
      "narrative_arc": "ìŠ¤í† ë¦¬ êµ¬ì¡° (5-8ë¬¸ì¥)",
      "scenes": [
        {{
          "timestamp": "ì‹œê°„ëŒ€",
          "scene": "ì¥ë©´ ë‚´ìš©",
          "visuals": "ë¹„ì£¼ì–¼ ìš”ì†Œ",
          "audio": "ì˜¤ë””ì˜¤ (ë‚´ë ˆì´ì…˜/ìŒì•…/íš¨ê³¼ìŒ)",
          "message": "ì „ë‹¬ ë©”ì‹œì§€"
        }}
      ],
      "style_guide": "ì˜ìƒ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ",
      "call_to_action": "í–‰ë™ ìœ ë„ ë¬¸êµ¬"
    }}
  }},
  
  "marketing_materials": {{
    "slogan": "ìŠ¬ë¡œê±´ (20-30ì)",
    "tagline": "íƒœê·¸ë¼ì¸ (40-60ì)",
    "elevator_pitch": "ì—˜ë¦¬ë² ì´í„° í”¼ì¹˜ (150-200ì)",
    "press_release": "ë³´ë„ìë£Œ í˜•ì‹ (300-500ì)",
    "social_media_posts": [
      {{
        "platform": "í”Œë«í¼",
        "content": "ê²Œì‹œë¬¼ ë‚´ìš©",
        "hashtags": ["í•´ì‹œíƒœê·¸"]
      }}
    ],
    "faq": [
      {{
        "question": "ìì£¼ ë¬»ëŠ” ì§ˆë¬¸",
        "answer": "ë‹µë³€"
      }}
    ]
  }},
  
  "performance_metrics": {{
    "kpi_framework": [
      {{
        "category": "ì§€í‘œ ì¹´í…Œê³ ë¦¬",
        "metric": "ì¸¡ì • í•­ëª©",
        "measurement_method": "ì¸¡ì • ë°©ë²•",
        "target_range": "ëª©í‘œ ë²”ìœ„ (êµ¬ê°„/ì¶”ì´)",
        "data_source": "ë°ì´í„° ì¶œì²˜"
      }}
    ],
    "success_criteria": ["ì„±ê³µ ê¸°ì¤€ 5-7ê°œ"],
    "monitoring_plan": {{
      "daily": "ì¼ê°„ ëª¨ë‹ˆí„°ë§ í•­ëª©",
      "weekly": "ì£¼ê°„ ëª¨ë‹ˆí„°ë§ í•­ëª©",
      "monthly": "ì›”ê°„ ëª¨ë‹ˆí„°ë§ í•­ëª©"
    }},
    "improvement_triggers": ["ê°œì„ ì´ í•„ìš”í•œ ì‹œì ì„ ì•Œë¦¬ëŠ” ì§€í‘œ 5-7ê°œ"]
  }},
  
  "stakeholder_management": {{
    "stakeholders": [
      {{
        "group": "ì´í•´ê´€ê³„ì ê·¸ë£¹",
        "interests": "ê´€ì‹¬ì‚¬",
        "engagement_strategy": "ì†Œí†µ ì „ëµ"
      }}
    ],
    "objection_handling": [
      {{
        "objection": "ì˜ˆìƒ ë°˜ëŒ€ ì˜ê²¬",
        "response": "ëŒ€ì‘ ë…¼ë¦¬"
      }}
    ]
  }}
}}

ìœ„ ìŠ¤í‚¤ë§ˆë¥¼ ì •í™•íˆ ë”°ë¼ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        raw_text = response.choices[0].message.content
        parsed_data = parse_json_response(raw_text)
        
        if parsed_data:
            return parsed_data, raw_text
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ì¬ì‹œë„
        retry_prompt = f"""
ì´ì „ ì‘ë‹µì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.
ì•„ë˜ ë‚´ìš©ì„ ì™„ë²½í•œ JSONìœ¼ë¡œ ë‹¤ì‹œ ì¶œë ¥í•´ì£¼ì„¸ìš”.

{raw_text}
"""
        
        retry_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": retry_prompt}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        
        retry_text = retry_response.choices[0].message.content
        retry_parsed = parse_json_response(retry_text)
        
        return retry_parsed, retry_text
        
    except Exception as e:
        return None, f"Error: {str(e)}"

def generate_image_prompt(brief: Dict[str, Any], style_override: str = "") -> str:
    concept = brief.get("concept", "")
    scene = brief.get("scene_description", "")
    style = brief.get("visual_style", "")
    message = brief.get("key_message", "")
    
    base_style = style_override if style_override else DEFAULT_IMAGE_STYLE
    
    prompt = f"""
{concept}

Scene description: {scene}

Visual style: {style}

{base_style}

Key message to convey: {message}

Important: Create realistic Korean people with natural, undistorted facial features.
No text or writing should appear anywhere in the image.
Focus on authentic Korean urban/suburban environment and genuine human expressions.
"""
    
    return prompt.strip()

def generate_video_prompts_3styles(brief: Dict[str, Any]) -> Dict[str, str]:
    """10ì´ˆ ì˜ìƒ 3ê°€ì§€ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    narrative = brief.get("narrative_arc", "")
    cta = brief.get("call_to_action", "")
    
    base_context = f"""
Duration: 10 seconds
Location: Modern South Korea
Language: Korean subtitles only
No English text visible
"""
    
    # ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬
    style1 = f"""
[ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬ ë¦¬ì–¼ë¦¬ì¦˜]

{base_context}

Visual Style:
- Handheld camera feel, natural movements
- Realistic lighting, documentary aesthetic
- Authentic Korean street scenes and people
- Observational approach, fly-on-the-wall style
- Natural color grading with slight desaturation

Camera:
- Medium shots and close-ups
- Slight camera shake for realism
- Follow subjects naturally

Audio:
- Natural ambient sounds (traffic, voices, city sounds)
- Minimal background music
- Natural Korean dialogue or voice-over

Narrative: {narrative}

Mood: Authentic, grounded, trustworthy
Pacing: Steady, observational
Final Message: {cta}

Technical: 24fps, cinematic aspect ratio, professional documentary style
"""
    
    # ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹±
    style2 = f"""
[ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹± ë“œë¼ë§ˆ]

{base_context}

Visual Style:
- Smooth cinematic camera movements (gimbal/slider)
- Dramatic lighting with warm and cool tones
- Korean urban landscape with cinematic composition
- Establishing shots of Seoul skyline or modern architecture
- Rich color grading inspired by Korean cinema

Camera:
- Wide establishing shots
- Slow push-ins and reveals
- Overhead/drone shots of Korean cityscape
- Smooth tracking shots

Audio:
- Emotional background music (orchestral or modern Korean OST style)
- Carefully designed sound effects
- Polished voice-over narration

Narrative: {narrative}

Mood: Inspiring, emotional, aspirational
Pacing: Dynamic with emotional beats
Final Message: {cta}

Technical: 24fps, anamorphic feel, cinematic color grade
"""
    
    # ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹
    style3 = f"""
[ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹]

{base_context}

Visual Style:
- Fast-paced dynamic cuts
- Modern Korean lifestyle and technology
- Bright, energetic visuals
- Clean, contemporary aesthetic
- Vibrant color grading with saturated tones

Camera:
- Quick cuts between multiple angles
- Time-lapse of Korean city life
- Dynamic camera movements
- Close-ups on details and faces
- Match cuts for visual rhythm

Audio:
- Upbeat modern Korean music
- Rhythmic sound design
- Quick voice-over or on-screen Korean text animations
- Sync with visual cuts

Narrative: {narrative}

Mood: Energetic, modern, forward-thinking
Pacing: Fast, rhythmic, attention-grabbing
Final Message: {cta}

Technical: 30fps or 60fps slow-motion elements, high contrast, vibrant colors
"""
    
    return {
        "documentary": style1,
        "cinematic": style2,
        "modern_dynamic": style3
    }

# ==================== ì´ë¯¸ì§€ ìƒì„± (Image Generator) ====================

def generate_policy_image(
    brief: dict,
    size: str = "1024x1024",
    quality: str = "standard"
) -> Optional[Tuple[Image.Image, bytes]]:
    """ì •ì±… ì´ë¯¸ì§€ ìƒì„± (brief ê¸°ë°˜)"""
    
    prompt = generate_image_prompt(brief)
    
    try:
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size=size,
            quality=quality,
            n=1,
            response_format="b64_json"
        )
        
        if response.data and len(response.data) > 0:
            b64_data = response.data[0].b64_json
            image_bytes = base64.b64decode(b64_data)
            image = Image.open(BytesIO(image_bytes))
            return (image, image_bytes)
        
        return None
        
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

def batch_generate_images(prompts: List[str], size: str = "1024x1024", quality: str = "standard") -> List[Tuple[Image.Image, bytes]]:
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ ìˆœì°¨ ìƒì„±"""
    results = []
    for prompt in prompts:
        try:
            response = client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size=size,
                quality=quality,
                n=1,
                response_format="b64_json"
            )
            
            if response.data and len(response.data) > 0:
                b64_data = response.data[0].b64_json
                image_bytes = base64.b64decode(b64_data)
                image = Image.open(BytesIO(image_bytes))
                results.append((image, image_bytes))
        except Exception as e:
            st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            continue
    
    return results

# ==================== PDF/ZIP ë‚´ë³´ë‚´ê¸° (Export Manager) ====================

def create_pdf_report(policy: Dict[str, Any], analysis: Dict[str, Any]) -> bytes:
    """í•œê¸€ ì •ì±… ë³´ê³ ì„œ PDF ìƒì„±"""
    
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    
    # í•œê¸€ í°íŠ¸ ë“±ë¡
    try:
        pdfmetrics.registerFont(UnicodeCIDFont('HYSMyeongJo-Medium'))
        font_name = 'HYSMyeongJo-Medium'
    except:
        font_name = 'Helvetica'
    
    # ì œëª©
    c.setFont(font_name, 20)
    c.drawString(50, height - 50, "ì •ì±… ë³´ê³ ì„œ")
    
    c.setFont(font_name, 14)
    c.drawString(50, height - 80, f"ì œëª©: {policy['title']}")
    c.drawString(50, height - 100, f"ì¹´í…Œê³ ë¦¬: {policy['category']}")
    c.drawString(50, height - 120, f"ëŒ€ìƒ: {policy['target_audience']}")
    
    c.setFont(font_name, 10)
    y_position = height - 160
    
    # ì •ì±… ì„¤ëª…
    if policy.get('description'):
        c.drawString(50, y_position, "ì •ì±… ì„¤ëª…:")
        y_position -= 20
        desc_lines = policy['description'][:200].split('\n')
        for line in desc_lines[:5]:
            c.drawString(60, y_position, line[:80])
            y_position -= 15
    
    c.showPage()
    c.save()
    
    buffer.seek(0)
    return buffer.read()

def create_zip_export(
    policy: Dict[str, Any],
    analysis: Dict[str, Any],
    images: List[bytes] = None,
    video_prompts: List[str] = None
) -> bytes:
    """ëª¨ë“  ìë£Œë¥¼ ZIPìœ¼ë¡œ ì••ì¶•"""
    
    buffer = BytesIO()
    
    with ZipFile(buffer, 'w') as zipf:
        # ì •ì±… ì •ë³´
        zipf.writestr("policy_info.json", json.dumps(policy, ensure_ascii=False, indent=2))
        
        # AI ë¶„ì„ ê²°ê³¼
        zipf.writestr("analysis_full.json", json.dumps(analysis, ensure_ascii=False, indent=2))
        
        # ì´ë¯¸ì§€
        if images:
            for idx, img_bytes in enumerate(images, 1):
                zipf.writestr(f"images/image_{idx}.png", img_bytes)
        
        # ì˜ìƒ í”„ë¡¬í”„íŠ¸
        if video_prompts:
            for idx, prompt in enumerate(video_prompts, 1):
                zipf.writestr(f"video_prompts/prompt_{idx}.txt", prompt)
        
        # README
        readme = f"""
ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨ - ê²°ê³¼ë¬¼ íŒ¨í‚¤ì§€

ì •ì±… ì œëª©: {policy['title']}
ìƒì„±ì¼: {policy['created_at']}

í¬í•¨ ë‚´ìš©:
- policy_info.json: ì •ì±… ê¸°ë³¸ ì •ë³´
- analysis_full.json: AI ë¶„ì„ ì „ì²´ ê²°ê³¼
- images/: ìƒì„±ëœ ì´ë¯¸ì§€
- video_prompts/: ì˜ìƒ ì œì‘ í”„ë¡¬í”„íŠ¸

ì‚¬ìš© ë°©ë²•:
1. analysis_full.jsonì„ ì—´ì–´ ì „ì²´ ë¶„ì„ ë‚´ìš© í™•ì¸
2. images í´ë”ì˜ ì´ë¯¸ì§€ í™œìš©
3. video_promptsì˜ í”„ë¡¬í”„íŠ¸ë¥¼ Runway, Pika ë“±ì— ì…ë ¥
"""
        zipf.writestr("README.txt", readme)
    
    buffer.seek(0)
    return buffer.read()

# ==================== Streamlit UI ====================

st.set_page_config(
    page_title="ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    defaults = {
        "current_policy_id": None,
        "current_analysis": None,
        "generated_images": [],
        "video_prompts_3styles": [],
        "workflow_step": "ê¸°íš",
        "show_results": False,
        "selected_category": "",
        "temp_selection": ""
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()
init_database()

st.markdown('<div class="main-header">ğŸ›ï¸ ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ì •ì±… ê¸°íšÂ·ì‹¤í–‰Â·í™ë³´Â·ì„±ê³¼ê´€ë¦¬ ìë™í™” ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("### ğŸ“‹ í”„ë¡œì„¸ìŠ¤ ë‹¨ê³„")
    
    steps = ["ê¸°íš", "ì‹¤í–‰", "í™ë³´", "ì„±ê³¼ê´€ë¦¬"]
    current_step_idx = steps.index(st.session_state.workflow_step)
    
    for idx, step in enumerate(steps):
        if idx < current_step_idx:
            st.success(f"âœ… {step}")
        elif idx == current_step_idx:
            st.info(f"â–¶ï¸ {step} (í˜„ì¬)")
        else:
            st.write(f"â¸ï¸ {step}")
    
    st.divider()
    
    st.markdown("### ğŸ“… ë‚ ì§œë³„ ì •ì±… ê²€ìƒ‰")
    
    search_type = st.radio("ê²€ìƒ‰ ë°©ì‹", ["ì „ì²´ ë³´ê¸°", "ë‚ ì§œ ì„ íƒ", "ë‚ ì§œ ë²”ìœ„"], horizontal=True)
    
    if search_type == "ë‚ ì§œ ì„ íƒ":
        selected_date = st.date_input("ë‚ ì§œ ì„ íƒ", value=date.today())
        policies = get_policies_by_date(selected_date.strftime("%Y-%m-%d"))
        st.caption(f"{selected_date.strftime('%Y-%m-%d')} ì •ì±… {len(policies)}ê±´")
    elif search_type == "ë‚ ì§œ ë²”ìœ„":
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("ì‹œì‘", value=date.today())
        with col2:
            end_date = st.date_input("ì¢…ë£Œ", value=date.today())
        policies = get_policies_by_date_range(
            start_date.strftime("%Y-%m-%d"),
            end_date.strftime("%Y-%m-%d")
        )
        st.caption(f"{len(policies)}ê±´ ë°œê²¬")
    else:
        policies = get_all_policies(limit=20)
        st.caption(f"ìµœê·¼ {len(policies)}ê±´")
    
    st.markdown("### ğŸ—‚ï¸ ì €ì¥ëœ ì •ì±…")
    
    if policies:
        for policy in policies:
            with st.expander(f"{policy['title'][:20]}..."):
                st.write(f"ğŸ“… {policy['created_at'][:10]}")
                st.write(f"ì¹´í…Œê³ ë¦¬: {policy['category']}")
                st.write(f"ëŒ€ìƒ: {policy['target_audience']}")
                if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", key=f"load_{policy['id']}"):
                    st.session_state.current_policy_id = policy['id']
                    contents = get_policy_contents(policy['id'])
                    if contents:
                        for content in contents:
                            if content['content_type'] == 'analysis':
                                st.session_state.current_analysis = content['content_data']
                    
                    media = get_generated_media(policy['id'])
                    st.session_state.generated_images = []
                    
                    for m in media:
                        if m['media_type'] == 'image' and m['media_data']:
                            img = Image.open(BytesIO(m['media_data']))
                            st.session_state.generated_images.append({
                                "image": img,
                                "bytes": m['media_data'],
                                "brief": "loaded"
                            })
                    
                    st.success(f"âœ… ì •ì±… ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
                    st.rerun()
    else:
        st.info("ì €ì¥ëœ ì •ì±…ì´ ì—†ìŠµë‹ˆë‹¤")
    
    st.divider()
    
    if st.button("ğŸ†• ìƒˆ ì •ì±… ì‹œì‘", use_container_width=True):
        for key in ["current_policy_id", "current_analysis", "generated_images", "video_prompts_3styles", "selected_category", "temp_selection"]:
            st.session_state[key] = [] if "images" in key or "prompts" in key else ("" if "category" in key or "selection" in key else None)
        st.session_state.workflow_step = "ê¸°íš"
        st.session_state.show_results = False
        st.rerun()

# ë©”ì¸ íƒ­
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“ ì •ì±… ì…ë ¥",
    "ğŸ¤– AI ë¶„ì„ ìƒì„±",
    "ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„±",
    "ğŸ¬ ì˜ìƒ í”„ë¡¬í”„íŠ¸",
    "ğŸ“Š ê²°ê³¼ ë° ë‚´ë³´ë‚´ê¸°"
])

with tab1:
    st.markdown("### 1ï¸âƒ£ ì •ì±… ê¸°ë³¸ ì •ë³´ ì…ë ¥")
    
    col1, col2 = st.columns(2)
    
    with col1:
        policy_title = st.text_input(
            "ì •ì±… ì œëª© *",
            placeholder="ì˜ˆ: ë„ì‹œ ëŒ€ê¸°ì§ˆ ì‹¤ì‹œê°„ ê´€ë¦¬ ì •ì±…",
            help="ì •ì±…ì˜ í•µì‹¬ì„ ë‹´ì€ ëª…í™•í•œ ì œëª©"
        )
        
        # ì¹´í…Œê³ ë¦¬ ë°ì´í„°ë² ì´ìŠ¤
        category_database = {
            "í™˜ê²½": {
                "ëŒ€ê¸°ì§ˆ": ["ë¯¸ì„¸ë¨¼ì§€ ì €ê°", "ëŒ€ê¸°ì˜¤ì—¼ ê´€ë¦¬", "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ë°°ì¶œê°€ìŠ¤ ê·œì œ"],
                "ìˆ˜ì§ˆ": ["í•˜ì²œ ì •í™”", "ìƒìˆ˜ë„ ê°œì„ ", "í•˜ìˆ˜ì²˜ë¦¬", "ìˆ˜ì§ˆ ëª¨ë‹ˆí„°ë§"],
                "íê¸°ë¬¼": ["ì“°ë ˆê¸° ê°ëŸ‰", "ì¬í™œìš©", "ìŒì‹ë¬¼ì“°ë ˆê¸°", "ì¼íšŒìš©í’ˆ ê·œì œ"],
                "ì—ë„ˆì§€": ["ì‹ ì¬ìƒì—ë„ˆì§€", "íƒœì–‘ê´‘", "í’ë ¥", "ì—ë„ˆì§€ íš¨ìœ¨í™”", "ì ˆì „"],
                "ê¸°í›„ë³€í™”": ["íƒ„ì†Œì¤‘ë¦½", "ì˜¨ì‹¤ê°€ìŠ¤ ê°ì¶•", "ê¸°í›„ ì ì‘", "ESG"]
            },
            "êµí†µ": {
                "ëŒ€ì¤‘êµí†µ": ["ë²„ìŠ¤ ë…¸ì„  ê°œí¸", "ì§€í•˜ì²  í™•ì¶©", "í™˜ìŠ¹ í¸ì˜", "ìš”ê¸ˆ ì •ì±…"],
                "ì£¼ì°¨": ["ê³µì˜ì£¼ì°¨ì¥", "ì£¼ì°¨ë‚œ í•´ì†Œ", "ë¶ˆë²•ì£¼ì°¨ ë‹¨ì†", "ê³µìœ ì£¼ì°¨"],
                "ë³´í–‰": ["ë³´í–‰ì ìš°ì„ ", "ë³´í–‰ë¡œ í™•ì¶©", "íš¡ë‹¨ë³´ë„ ê°œì„ ", "ë¬´ì¥ì•  ë„ë¡œ"],
                "ìì „ê±°": ["ìì „ê±° ë„ë¡œ", "ê³µìœ ìì „ê±°", "ìì „ê±° ì£¼ì°¨ì¥", "ì•ˆì „ ì¸í”„ë¼"]
            },
            "ë³µì§€": {
                "ë…¸ì¸ë³µì§€": ["ê²½ë¡œë‹¹ ì§€ì›", "ëŒë´„ ì„œë¹„ìŠ¤", "ì¼ìë¦¬ ì°½ì¶œ", "ê±´ê°•ê´€ë¦¬", "ì¹˜ë§¤ ì˜ˆë°©"],
                "ì•„ë™ë³µì§€": ["ë³´ìœ¡ ì§€ì›", "ë†€ì´í„° í™•ì¶©", "ì•„ë™í•™ëŒ€ ì˜ˆë°©", "ë°©ê³¼í›„ ëŒë´„"],
                "ì²­ë…„ë³µì§€": ["ì£¼ê±° ì§€ì›", "ì·¨ì—… ì§€ì›", "ì²­ë…„ìˆ˜ë‹¹", "ì°½ì—… ì§€ì›"]
            },
            "êµìœ¡": {
                "í•™êµêµìœ¡": ["êµìœ¡ê³¼ì • ê°œì„ ", "í•™êµì‹œì„¤ í˜„ëŒ€í™”", "ë¬´ìƒê¸‰ì‹", "ëŒë´„êµì‹¤"],
                "í‰ìƒêµìœ¡": ["ì„±ì¸ êµìœ¡", "ì§ì—…í›ˆë ¨", "ì˜¨ë¼ì¸ ê°•ì¢Œ", "í•™ìŠµ ì§€ì›"]
            },
            "ì•ˆì „": {
                "ì¬ë‚œì•ˆì „": ["í™”ì¬ ì˜ˆë°©", "ì§€ì§„ ëŒ€ë¹„", "íƒœí’ ëŒ€ë¹„", "ì¬ë‚œ ëŒ€ì‘ í›ˆë ¨"],
                "ë²”ì£„ì˜ˆë°©": ["CCTV í™•ì¶©", "ì•ˆì‹¬ê·€ê°€", "í•™êµí­ë ¥ ì˜ˆë°©", "ì„±ë²”ì£„ ì˜ˆë°©"]
            },
            "ê²½ì œ": {
                "ì¼ìë¦¬": ["ì¼ìë¦¬ ì°½ì¶œ", "êµ¬ì§ ì§€ì›", "ì§ì—… í›ˆë ¨", "ê³ ìš© ì•ˆì •"],
                "ì°½ì—…": ["ì°½ì—… êµìœ¡", "ìê¸ˆ ì§€ì›", "ë©˜í† ë§", "ê³µìœ  ì˜¤í”¼ìŠ¤"]
            }
        }
        
        # ì„ íƒ ë²„íŠ¼ì´ ëˆŒë ¸ì„ ë•Œ
        if "temp_selection" in st.session_state and st.session_state.temp_selection:
            st.session_state.selected_category = st.session_state.temp_selection
            st.session_state.temp_selection = ""
        
        # ì •ì±… ì¹´í…Œê³ ë¦¬ ì…ë ¥ì°½
        policy_category = st.text_input(
            "ì •ì±… ì¹´í…Œê³ ë¦¬ *",
            value=st.session_state.selected_category if st.session_state.selected_category else "",
            placeholder="ì˜ˆ: í™”ì¬, ì²­ë…„, ì£¼ì°¨ ë“± ì…ë ¥í•˜ë©´ ìë™ì™„ì„±ë©ë‹ˆë‹¤",
            help="í•œ ê¸€ìì”© ì…ë ¥í•˜ë©´ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ê°€ ìë™ìœ¼ë¡œ ì¶”ì²œë©ë‹ˆë‹¤"
        )
        
        # ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ë©´ ì—…ë°ì´íŠ¸
        if policy_category != st.session_state.selected_category:
            st.session_state.selected_category = policy_category
        
        # ì‹¤ì‹œê°„ ìë™ì™„ì„±
        if policy_category and len(policy_category) > 0:
            autocomplete_suggestions = []
            
            for main_cat, sub_cats in category_database.items():
                for sub_cat, items in sub_cats.items():
                    for item in items:
                        full_path = f"{main_cat} > {sub_cat} > {item}"
                        if policy_category.lower() in full_path.lower():
                            autocomplete_suggestions.append(full_path)
            
            if autocomplete_suggestions:
                st.markdown("##### ğŸ’¡ ìë™ì™„ì„± ì¶”ì²œ")
                st.caption(f"{len(autocomplete_suggestions)}ê°œ í•­ëª© ë°œê²¬ (ìµœëŒ€ 10ê°œ í‘œì‹œ)")
                
                for idx, suggestion in enumerate(autocomplete_suggestions[:10]):
                    cols = st.columns([5, 1])
                    with cols[0]:
                        st.markdown(f"âœ¨ {suggestion}")
                    with cols[1]:
                        if st.button("ì„ íƒ", key=f"autocomplete_{idx}", use_container_width=True):
                            st.session_state.temp_selection = suggestion
                            st.rerun()
                
                if len(autocomplete_suggestions) > 10:
                    st.caption(f"+ {len(autocomplete_suggestions) - 10}ê°œ ë” ìˆìŠµë‹ˆë‹¤.")
        
        target_audience = st.selectbox(
            "ì£¼ìš” ëŒ€ìƒ *",
            options=list(TARGET_AUDIENCES.keys()),
            help="ì •ì±…ì˜ ì£¼ìš” ëŒ€ìƒ ê·¸ë£¹"
        )
        
        if target_audience in TARGET_AUDIENCES:
            audience_info = TARGET_AUDIENCES[target_audience]
            st.info(f"**í†¤**: {audience_info['tone']}\n\n**ì´ˆì **: {audience_info['focus']}")
    
    with col2:
        policy_description = st.text_area(
            "ì •ì±… ì„¤ëª… *",
            height=150,
            placeholder="ì •ì±…ì˜ ë°°ê²½, ëª©ì , ê¸°ëŒ€ íš¨ê³¼ ë“±ì„ ìì„¸íˆ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        keywords = st.text_input(
            "ê°•ì¡° í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            placeholder="ì˜ˆ: ì‹œë¯¼ì°¸ì—¬, ë°ì´í„°ê¸°ë°˜, ì§€ì†ê°€ëŠ¥ì„±"
        )
        
        constraints = st.text_area(
            "ì œì•½ ì¡°ê±´ (ì„ íƒ)",
            height=100,
            placeholder="ì˜ˆ: ì˜ˆì‚° 1ì–µ ì´ë‚´, 3ê°œì›” ì‹œë²”ìš´ì˜"
        )
    
    content_package = st.selectbox(
        "ì½˜í…ì¸  íŒ¨í‚¤ì§€",
        options=list(CONTENT_PACKAGES.keys())
    )
    
    st.info(f"**ì„ íƒí•œ íŒ¨í‚¤ì§€ í¬í•¨ í•­ëª©**: {', '.join(CONTENT_PACKAGES[content_package])}")
    
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        if st.button("ğŸ’¾ ì •ì±… ì €ì¥", use_container_width=True):
            if not policy_title or not policy_description:
                st.error("ì •ì±… ì œëª©ê³¼ ì„¤ëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            else:
                policy_id = create_policy(
                    title=policy_title,
                    category=policy_category,
                    target_audience=target_audience,
                    description=policy_description
                )
                st.session_state.current_policy_id = policy_id
                st.success(f"âœ… ì •ì±…ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ (ID: {policy_id})")
                st.session_state.workflow_step = "ì‹¤í–‰"
    
    with col2:
        if st.button("ğŸš€ AI ë¶„ì„ ìƒì„±", use_container_width=True):
            if not policy_title or not policy_description:
                st.error("ì •ì±… ì œëª©ê³¼ ì„¤ëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            else:
                try:
                    if not st.session_state.current_policy_id:
                        policy_id = create_policy(
                            title=policy_title,
                            category=policy_category,
                            target_audience=target_audience,
                            description=policy_description
                        )
                        st.session_state.current_policy_id = policy_id
                    
                    with st.spinner("AIê°€ ì •ì±…ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (30-60ì´ˆ ì†Œìš”)"):
                        analysis, raw = generate_policy_analysis(
                            title=policy_title,
                            category=policy_category,
                            target_audience=target_audience,
                            description=policy_description,
                            keywords=keywords,
                            constraints=constraints
                        )
                        
                        if analysis:
                            st.session_state.current_analysis = analysis
                            save_policy_content(
                                st.session_state.current_policy_id,
                                "analysis",
                                analysis
                            )
                            st.success("âœ… AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.session_state.show_results = True
                            st.session_state.workflow_step = "í™ë³´"
                            st.balloons()
                        else:
                            st.error(f"AI ë¶„ì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

with tab2:
    st.markdown("### 2ï¸âƒ£ AI ìƒì„± ê²°ê³¼")
    
    if st.session_state.current_analysis:
        analysis = st.session_state.current_analysis
        
        with st.expander("ğŸ“‹ ì •ì±… ê¸°íš", expanded=True):
            if "policy_planning" in analysis:
                planning = analysis["policy_planning"]
                st.markdown(f"**ëª©í‘œ**: {planning.get('objective', '')}")
                st.markdown(f"**ëŒ€ìƒ ë¶„ì„**: {planning.get('target_analysis', '')}")
                
                st.markdown("**í•µì‹¬ ì „ëµ**:")
                for idx, strategy in enumerate(planning.get("key_strategies", []), 1):
                    st.write(f"{idx}. {strategy}")
        
        with st.expander("âš™ï¸ ì‹¤í–‰ ê³„íš"):
            if "execution_plan" in analysis:
                execution = analysis["execution_plan"]
                
                action_items = execution.get("action_items", [])
                if action_items:
                    st.markdown("**ì‹¤í–‰ í•­ëª©**:")
                    for item in action_items:
                        st.markdown(f"""
**{item.get('phase', '')}**
- ì‹¤í–‰ ë‚´ìš©: {item.get('action', '')}
- ë‹´ë‹¹: {item.get('responsible', '')}
- ê¸°ê°„: {item.get('timeline', '')}
""")
        
        with st.expander("ğŸ“£ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ"):
            if "communication_strategy" in analysis:
                comm = analysis["communication_strategy"]
                
                st.markdown("**í•µì‹¬ ë©”ì‹œì§€**:")
                for msg in comm.get("key_messages", []):
                    st.write(f"â€¢ {msg}")
        
        with st.expander("ğŸ¨ ì½˜í…ì¸  ì œì‘ ë¸Œë¦¬í”„"):
            if "content_briefs" in analysis:
                briefs = analysis["content_briefs"]
                
                st.markdown("### ì´ë¯¸ì§€ ë¸Œë¦¬í”„ 1")
                if "image_brief_1" in briefs:
                    brief1 = briefs["image_brief_1"]
                    st.write(f"**ì»¨ì…‰**: {brief1.get('concept', '')}")
                    st.write(f"**ì¥ë©´**: {brief1.get('scene_description', '')}")
                
                st.markdown("### ì´ë¯¸ì§€ ë¸Œë¦¬í”„ 2")
                if "image_brief_2" in briefs:
                    brief2 = briefs["image_brief_2"]
                    st.write(f"**ì»¨ì…‰**: {brief2.get('concept', '')}")
                    st.write(f"**ì¥ë©´**: {brief2.get('scene_description', '')}")
    
    else:
        st.info("ë¨¼ì € 'ì •ì±… ì…ë ¥' íƒ­ì—ì„œ ì •ì±… ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  AI ë¶„ì„ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")

with tab3:
    st.markdown("### 3ï¸âƒ£ ì´ë¯¸ì§€ ìë™ ìƒì„±")
    
    if st.session_state.current_analysis and "content_briefs" in st.session_state.current_analysis:
        briefs = st.session_state.current_analysis["content_briefs"]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            image_size = st.selectbox("ì´ë¯¸ì§€ í¬ê¸°", IMAGE_SIZES)
        
        with col2:
            image_quality = st.selectbox("í’ˆì§ˆ", ["standard", "hd"])
        
        with col3:
            num_images = st.number_input("ìƒì„± ê°œìˆ˜", min_value=1, max_value=4, value=2)
        
        st.divider()
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ–¼ï¸ ì´ë¯¸ì§€ 1 ìƒì„±", use_container_width=True):
                if "image_brief_1" in briefs:
                    with st.spinner("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (20-40ì´ˆ)"):
                        result = generate_policy_image(
                            briefs["image_brief_1"],
                            size=image_size,
                            quality=image_quality
                        )
                        if result:
                            img, img_bytes = result
                            st.session_state.generated_images.append({
                                "image": img,
                                "bytes": img_bytes,
                                "brief": "image_brief_1"
                            })
                            
                            if st.session_state.current_policy_id:
                                save_generated_media(
                                    st.session_state.current_policy_id,
                                    "image",
                                    img_bytes,
                                    generate_image_prompt(briefs["image_brief_1"]),
                                    {"size": image_size, "quality": image_quality}
                                )
                            
                            st.success("âœ… ì´ë¯¸ì§€ 1 ìƒì„± ì™„ë£Œ!")
                            st.rerun()
                        else:
                            st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        with col2:
            if st.button("ğŸ–¼ï¸ ì´ë¯¸ì§€ 2 ìƒì„±", use_container_width=True):
                if "image_brief_2" in briefs:
                    with st.spinner("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (20-40ì´ˆ)"):
                        result = generate_policy_image(
                            briefs["image_brief_2"],
                            size=image_size,
                            quality=image_quality
                        )
                        if result:
                            img, img_bytes = result
                            st.session_state.generated_images.append({
                                "image": img,
                                "bytes": img_bytes,
                                "brief": "image_brief_2"
                            })
                            
                            if st.session_state.current_policy_id:
                                save_generated_media(
                                    st.session_state.current_policy_id,
                                    "image",
                                    img_bytes,
                                    generate_image_prompt(briefs["image_brief_2"]),
                                    {"size": image_size, "quality": image_quality}
                                )
                            
                            st.success("âœ… ì´ë¯¸ì§€ 2 ìƒì„± ì™„ë£Œ!")
                            st.rerun()
                        else:
                            st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        st.divider()
        
        if st.session_state.generated_images:
            st.markdown(f"### ìƒì„±ëœ ì´ë¯¸ì§€ ({len(st.session_state.generated_images)}ì¥)")
            
            cols = st.columns(2)
            for idx, img_data in enumerate(st.session_state.generated_images):
                with cols[idx % 2]:
                    st.image(img_data["image"], use_column_width=True)
                    st.caption(f"ì´ë¯¸ì§€ {idx+1}")
                    
                    buffer = BytesIO(img_data["bytes"])
                    st.download_button(
                        f"ğŸ’¾ ì´ë¯¸ì§€ {idx+1} ë‹¤ìš´ë¡œë“œ",
                        buffer,
                        file_name=f"policy_image_{idx+1}.png",
                        mime="image/png",
                        key=f"download_img_{idx}"
                    )
        else:
            st.info("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë ¤ë©´ ìœ„ì˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
    
    else:
        st.info("ë¨¼ì € AI ë¶„ì„ì„ ìƒì„±í•´ì£¼ì„¸ìš”")

with tab4:
    st.markdown("### 4ï¸âƒ£ ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„± (10ì´ˆ 3ì¢… ìŠ¤íƒ€ì¼)")
    
    if st.session_state.current_analysis and "content_briefs" in st.session_state.current_analysis:
        briefs = st.session_state.current_analysis["content_briefs"]
        
        if "video_brief" in briefs:
            video_brief = briefs["video_brief"]
            
            st.info("ğŸ¬ **10ì´ˆ ì˜ìƒ 3ê°€ì§€ ìŠ¤íƒ€ì¼**ì´ ìë™ ìƒì„±ë©ë‹ˆë‹¤: ë‹¤íë©˜í„°ë¦¬, ì‹œë„¤ë§ˆí‹±, ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹")
            
            if st.button("ğŸ¬ 10ì´ˆ ì˜ìƒ 3ì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±", use_container_width=True, type="primary"):
                with st.spinner("3ê°€ì§€ ìŠ¤íƒ€ì¼ì˜ ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘..."):
                    prompts_3styles = generate_video_prompts_3styles(video_brief)
                    
                    if "video_prompts_3styles" not in st.session_state:
                        st.session_state.video_prompts_3styles = []
                    
                    st.session_state.video_prompts_3styles.append(prompts_3styles)
                    st.success("âœ… 10ì´ˆ ì˜ìƒ 3ì¢… í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.balloons()
            
            st.divider()
            
            # 3ì¢… ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
            if "video_prompts_3styles" in st.session_state and st.session_state.video_prompts_3styles:
                st.markdown("### ğŸ“¹ ìƒì„±ëœ ì˜ìƒ í”„ë¡¬í”„íŠ¸")
                
                for set_idx, prompt_set in enumerate(st.session_state.video_prompts_3styles):
                    st.markdown(f"#### ì„¸íŠ¸ {set_idx + 1}")
                    
                    # ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬
                    with st.expander("ğŸ¥ ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬ ë¦¬ì–¼ë¦¬ì¦˜", expanded=True):
                        st.text_area(
                            "í”„ë¡¬í”„íŠ¸ (ë‹¤íë©˜í„°ë¦¬)",
                            prompt_set["documentary"],
                            height=400,
                            key=f"video_doc_{set_idx}"
                        )
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.download_button(
                                "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                prompt_set["documentary"],
                                file_name=f"video_documentary_{set_idx+1}.txt",
                                mime="text/plain",
                                key=f"download_doc_{set_idx}",
                                use_container_width=True
                            )
                        with col2:
                            st.link_button("ğŸš€ Runway", VIDEO_PLATFORMS["Runway"], use_container_width=True)
                        with col3:
                            st.link_button("ğŸ¥ Pika", VIDEO_PLATFORMS["Pika"], use_container_width=True)
                    
                    # ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹±
                    with st.expander("ğŸ¬ ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹± ë“œë¼ë§ˆ", expanded=True):
                        st.text_area(
                            "í”„ë¡¬í”„íŠ¸ (ì‹œë„¤ë§ˆí‹±)",
                            prompt_set["cinematic"],
                            height=400,
                            key=f"video_cine_{set_idx}"
                        )
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.download_button(
                                "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                prompt_set["cinematic"],
                                file_name=f"video_cinematic_{set_idx+1}.txt",
                                mime="text/plain",
                                key=f"download_cine_{set_idx}",
                                use_container_width=True
                            )
                        with col2:
                            st.link_button("ğŸš€ Runway", VIDEO_PLATFORMS["Runway"], use_container_width=True)
                        with col3:
                            st.link_button("ğŸ¥ Pika", VIDEO_PLATFORMS["Pika"], use_container_width=True)
                    
                    # ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹
                    with st.expander("âš¡ ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹", expanded=True):
                        st.text_area(
                            "í”„ë¡¬í”„íŠ¸ (ëª¨ë˜)",
                            prompt_set["modern_dynamic"],
                            height=400,
                            key=f"video_modern_{set_idx}"
                        )
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.download_button(
                                "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                prompt_set["modern_dynamic"],
                                file_name=f"video_modern_{set_idx+1}.txt",
                                mime="text/plain",
                                key=f"download_modern_{set_idx}",
                                use_container_width=True
                            )
                        with col2:
                            st.link_button("ğŸš€ Runway", VIDEO_PLATFORMS["Runway"], use_container_width=True)
                        with col3:
                            st.link_button("ğŸ¥ Pika", VIDEO_PLATFORMS["Pika"], use_container_width=True)
                    
                    st.divider()
            else:
                st.info("ìœ„ì˜ '10ì´ˆ ì˜ìƒ 3ì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
        
        else:
            st.info("ì˜ìƒ ë¸Œë¦¬í”„ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    else:
        st.info("ë¨¼ì € AI ë¶„ì„ì„ ìƒì„±í•´ì£¼ì„¸ìš”")

with tab5:
    st.markdown("### 5ï¸âƒ£ ê²°ê³¼ ë° ë‚´ë³´ë‚´ê¸°")
    
    if st.session_state.current_policy_id and st.session_state.current_analysis:
        policy = get_policy(st.session_state.current_policy_id)
        
        st.markdown("#### ì •ì±… ì •ë³´")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì •ì±… ID", policy['id'])
        with col2:
            st.metric("ì¹´í…Œê³ ë¦¬", policy['category'])
        with col3:
            st.metric("ëŒ€ìƒ", policy['target_audience'])
        with col4:
            st.metric("ìƒíƒœ", policy['status'])
        
        st.markdown(f"**ì œëª©**: {policy['title']}")
        st.markdown(f"**ì„¤ëª…**: {policy['description'][:100]}...")
        
        st.divider()
        
        st.markdown("#### ìƒì„±ëœ ì½˜í…ì¸ ")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ë¯¸ì§€", f"{len(st.session_state.generated_images)}ì¥")
        with col2:
            video_count = len(st.session_state.video_prompts_3styles)
            st.metric("ì˜ìƒ í”„ë¡¬í”„íŠ¸", f"{video_count}ì„¸íŠ¸")
        with col3:
            st.metric("AI ë¶„ì„", "ì™„ë£Œ" if st.session_state.current_analysis else "ì—†ìŒ")
        
        st.divider()
        
        st.markdown("#### ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“„ PDF ë³´ê³ ì„œ", use_container_width=True):
                with st.spinner("PDFë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    pdf_bytes = create_pdf_report(policy, st.session_state.current_analysis)
                    st.download_button(
                        "ğŸ’¾ PDF ë‹¤ìš´ë¡œë“œ",
                        pdf_bytes,
                        file_name=f"policy_report_{policy['id']}.pdf",
                        mime="application/pdf",
                        use_container_width=True
                    )
        
        with col2:
            if st.button("ğŸ“¦ ì „ì²´ ZIP", use_container_width=True):
                with st.spinner("ZIP íŒŒì¼ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    image_bytes = [img['bytes'] for img in st.session_state.generated_images]
                    
                    zip_bytes = create_zip_export(
                        policy,
                        st.session_state.current_analysis,
                        images=image_bytes
                    )
                    
                    st.download_button(
                        "ğŸ’¾ ZIP ë‹¤ìš´ë¡œë“œ",
                        zip_bytes,
                        file_name=f"policy_package_{policy['id']}.zip",
                        mime="application/zip",
                        use_container_width=True
                    )
    
    else:
        st.info("ì •ì±…ì„ ìƒì„±í•˜ê³  AI ë¶„ì„ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”")
